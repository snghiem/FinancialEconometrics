library("Ecdat")
library("fGarch")
library("evir")
library("evir")
library("evir")
libary("forecast")
library("forecast")
install.packages("forecast")
library("forecast")
data(CRSPday, package="Ecdat")
data(bmw)
summary(bmw)
length(bmw)
summary(bmw)
length(bmw)
summary(bmw)
summary(bmw)
length(bmw)
summary(bmw)
summary(bmw)
summary(bmw)
length(bmw)
plot(bmw)
acf(bmw)
summary(bmw)
length(bmw)
plot(bmw)
acf(bmw)
plot(bmw)
acf(bmw)
plot(bmw)
plot(bmw)
acf(bmw)
Box.test(x=bmw, lag=5, type="Ljung-Box")
fitAR1 = arima(bmw, order = c(1,0,0))
?acf
setwd("D:/sony/FinEcon")
dat = read.csv("datasets/Stock_bond.csv", header=TRUE)
dim(dat)
head(dat)
names(dat)
attach(dat)
par(mfrow=c(1,2))
plot(GM_AC)
plot(F_AC)
# problem 1
n = dim(dat)[1]
GM.return = GM_AC[2:n]/GM_AC[1:(n-1)] -1
F.return = F_AC[2:n]/F_AC[1:(n-1)] -1
par(mfrow=c(1,1))
plot(GM.return, F.return)
# it has a very weak positive correlation
# there are quite a few outliers
# it looks like a black hole.
#problem 2
GM.logreturn = log(GM.return+1)
summary(GM.logreturn)
plot(GM.return, GM.logreturn)
# they are quite highly correlated
cor(GM.return, GM.logreturn)
summary(dat)
setwd("D:/sony/FinEcon")
dat = read.csv("datasets/Stock_bond.csv", header=TRUE)
dim(dat)
head(dat)
names(dat)
attach(dat)
par(mfrow=c(1,2))
plot(GM_AC)
plot(F_AC)
n = dim(dat)[1]
GM.return = GM_AC[2:n]/GM_AC[1:(n-1)] -1
F.return = F_AC[2:n]/F_AC[1:(n-1)] -1
par(mfrow=c(1,1))
plot(GM.return, F.return)
cor(GM.return, GM.logreturn)
GM.logreturn = log(GM.return+1)
summary(GM.logreturn)
plot(GM.return, GM.logreturn)
# they are quite highly correlated
cor(GM.return, GM.logreturn)
#summary(dat)
summary(dat)
GM.logreturn = log(GM.return+1)
summary(GM.logreturn)
plot(GM.return, GM.logreturn)
# they are quite highly correlated
cor(GM.return, GM.logreturn)
summary(dat)
GM.logreturn = log(GM.return+1)
summary(GM.logreturn)
plot(GM.return, GM.logreturn)
cor(GM.return, GM.logreturn)
summary(dat)
niter = 1e5 # number of iterations
below = rep(0, niter) # set up storage
set.seed(2016)
for (i in 1:niter) {
# create log normals for 45 days
r =rnorm(45, mean =.05/253, sd = .23/sqrt(253))
# this is the amount after 45 days
logPrice = log(1e6) +cumsum(r)
# minimum price over next 45 days
minlogP = min(logPrice)
#we only consider MINIMUM log price less than log(950,000)
# only consider the minimums
# for sure it's less than???
below[i] = as.numeric(minlogP <log(950000))
}
mean(below)
library(evir)
library(fGarch)
data(bmw)
start_bmw = c(mean(bmw),sd(bmw),4)
loglik_bmw = function(theta)
{
-sum(log(dstd(bmw,mean=theta[1],sd=theta[2],nu=theta[3])))
}
mle_bmw = optim(start_bmw, loglik_bmw, hessian=T)
FishInfo_bmw = solve(mle_bmw$hessian)
library(MASS)
plot(density(bmw))
# to fit the classical t-distribution
fitdistr(bmw, 't')
#to fit a F-S skewed t-distribution
sstdFit(bmw)
# to fit a generalized error distribution
gedFit(bmw)
FishInfo_bmw
?sstdFit
library("Ecdat")
library("Ecdat")
library("fGarch")
library("evir")
library("forecast")
data(CRSPday, package="Ecdat")
data(bmw)
summary(bmw)
length(bmw)
summary(bmw)
length(bmw)
plot(bmw)
acf(bmw)
Box.test(x=bmw, lag=5, type="Ljung-Box")
fitAR1 = arima(bmw, order = c(1,0,0))
?acf
fitAR1
acf(fitAR1$resid)
plot(fitAR1$resid)
Box.test(fitAR1$resid,lag=5,type="Ljung-Box",fitdf=1)
data(Mishkin)
summary(Mishkin)
inflation=Mishkin[,1]
summary(Mishkin)
?Mishin
?Mishkin
summary(Mishkin)
inflation = Mishkin[,1]
plot(inflation)
acf(inflation)
fitAR1= arima(inflation, order=c(1,0,1))
plot(inflation)
# it doesn't seem stationary
acf(inflation)
# The ACF decays to zero slowly, showing that this is a sign of either nonstationarity or possibly of stationarity with long-memory dependence.
fitAR1= arima(inflation, order=c(1,0,1))
acf(fitAR1$resid)
Box.test(fitAR1$resid, lag=5, type="Ljung-Box", fitdf=1)
?diff
library(timeSeries)
library(timeSeries)
?diff
?st.mple # fitting functions
library(copula)
library(sn)
library(ks)
setwd("D:/Sony/FinEcon/datasets")
dat = read.csv("GasFlowData.csv", header=T)
summary(dat)
dat=dat/10000 # just to reduce the scale of the data
n = nrow(dat)
x1=dat$Flow1
fit1 = st.mple(matrix(1,n,1), y= x1, dp=c(mean(x1), sd(x1), 0, 10))
?st.mple # fitting functions
fit1
est1 = fit1$dp
est1
u1 = pst(x1, dp=est1)
?pst # Skew-t Distribution
x2=dat$Flow2
fit2 = st.mple(matrix(1,n,1), y= x2, dp=c(mean(x2), sd(x2), 0, 10))
est2 = fit2$dp
est2
u2 = pst(x2, dp=est2)
U.hat = cbind(u1,u2)
fhatU=kde(x=U.hat,H=Hscv(x=U.hat))
?kde
plot(fhatU, cont=seq(10,80,10)) # plot contours
?cor.test # Test for Association/Correlation Between Paired Samples
cor.test(u1, u2, method = "kendall")
omega = sin(-0.234435*pi/2)
Ct = fitCopula(copula=tCopula(dim=2), data=U.hat, method="ml", start=c(omega,10))
Ct@estimate # here I need to use @ instead of $
loglikCopula(param=Ct@estimate, u=U.hat, copula=tCopula(dim=2))
AIC.t = -2*.Last.value+2*length(Ct@estimate)
AIC.t
?diag
library("sn")
library("fGarch")
library("Ecdat")
dim(CRSPday)
summary(CRSPday)
?CRSPday #Center for Research in Security Prices
cov(CRSPday[,4:7]) # the diagonal values shoudl be the variance of each parameter
cor(CRSPday[,4:7])
pairs(CRSPday[,4:7])
omega = diag(2)
omega
omega[2,1]= omega[1,2]=.9
omega
alpha = c(1,1) # here alpha represents the skewness of two variables
?rmst # multivariate skew-t distribution
x = rmst(1000, xi = c(0,0), omega, alpha, nu =3)
plot(x[,1],x[,2])
omega[2,1]= omega[1,2]=0
x = rmst(1000, xi = c(0,0), omega, alpha, nu =3)
plot(x[,1],x[,2])
x = rmst(1000, xi = c(0,0), omega, alpha, nu =5)
plot(x[,1],x[,2])
x = rmst(1000, xi = c(0,0), omega, alpha, nu =10)
plot(x[,1],x[,2])
?mst.mple
fit1 = mst.mple(y =CRSPday[,4:7], penalty = NULL)
fit1
plot(density(CRSPday[,4]))
plot(density(CRSPday[,5]))
plot(density(CRSPday[,6]))
plot(density(CRSPday[,7]))
dat = CRSPday[,4:7]
df = seq(5.25, 6.75, 0.01)
n=length(df)
loglik = rep(0,n)
library(mnormt)
library(MASS)
?dmt # probability desnity function for the multivariate Student's t distribution
?cov.trob # covariance estimation for multivariate t-distribution
for (i in 1:n){
fit = cov.trob(dat, nu =df[i]) # try to fit the covariance matrix
loglik[i] = sum(log(dmt(dat, mean=fit$center, S=fit$cov, df =df[i])))
}
aic.t = -2*loglik + 2* (4+10) #because there are no alphas and here we have a fixed nu.
plot(df, aic.t)
df[which.min(aic.t)]
?df
plot(df, loglik)
df[which.max(loglik)]
cov.trob(dat, nu=5.91)
?cov.trob # covariance estimation for multivariate t-distribution
?nlm() # non-linear minimization using a Newton-type algorithm
